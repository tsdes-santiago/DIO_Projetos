from langchain_community.llms import Ollama
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.messages import HumanMessage, AIMessage
from langchain_ollama import OllamaEmbeddings  # Importa√ß√£o correta para embeddings
import os

# 1. Verificar e instalar depend√™ncias necess√°rias
try:
    from langchain_ollama import OllamaEmbeddings
except ImportError:
    print("Instalando pacote langchain-ollama...")
    os.system("pip install -U langchain-ollama")
    from langchain_ollama import OllamaEmbeddings

# 2. Carregar o PDF com informa√ß√µes de viagem
def load_pdf_knowledge(pdf_path):
    try:
        loader = PyPDFLoader(pdf_path)
        pages = loader.load()
        
        # Dividir o texto em chunks menores
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        docs = text_splitter.split_documents(pages)
        
        # Criar vetorstore com embeddings atualizados
        embeddings = OllamaEmbeddings(model="llama3:8b-instruct-q4_K_M")
        vectorstore = FAISS.from_documents(docs, embeddings)
        return vectorstore
    except Exception as e:
        print(f"Erro ao carregar PDF: {e}")
        return None

# 3. Configura√ß√£o do sistema
pdf_path = "Guia-FamiÃÅlia_V3_menor.pdf"  # Substitua pelo seu arquivo PDF
knowledge_base = load_pdf_knowledge(pdf_path)

# Configurar LLM
llm = Ollama(
    model="llama3:8b-instruct-q4_K_M",
    temperature=0.7
)

# 4. Configura√ß√£o do prompt
prompt = ChatPromptTemplate.from_messages([
    ("system", """Voc√™ √© um assistente de viagens chamado Viajero. Responda com base nas informa√ß√µes fornecidas e no hist√≥rico da conversa.

INFORMA√á√ïES RELEVANTES DO PDF:
{context}

Siga estas regras:
1. Se o destino n√£o estiver no PDF, diga: "Desculpe, n√£o tenho informa√ß√µes sobre esse destino em meu banco de dados."
2. Se encontrar o destino, forne√ßa detalhes √∫teis e relevantes
3. Mantenha um tom amig√°vel e profissional"""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}")
])

# 5. Fun√ß√£o para busca sem√¢ntica no PDF
def search_in_pdf(query):
    try:
        if knowledge_base:
            docs = knowledge_base.similarity_search(query, k=3)
            return "\n---\n".join([doc.page_content for doc in docs])
        return "Base de conhecimento n√£o dispon√≠vel"
    except Exception as e:
        print(f"Erro na busca: {e}")
        return "Erro ao acessar base de conhecimento"

# 6. Chatbot principal
def travel_chatbot():
    print("üåç Viajero - Assistente de Viagens Baseado em PDF üåç")
    print(f"Base de conhecimento: {'Carregada com sucesso' if knowledge_base else 'N√£o dispon√≠vel'}")
    print("Digite 'sair' a qualquer momento para encerrar.\n")
    
    # Inicializar hist√≥rico de chat
    chat_history = ChatMessageHistory()
    
    while True:
        user_input = input("\nViajante: ").strip()
        
        if user_input.lower() in ['sair', 'exit', 'quit']:
            print("\nAt√© logo! Boas viagens! ‚úàÔ∏è")
            break
            
        # Buscar informa√ß√µes relevantes no PDF
        context = search_in_pdf(user_input)
        
        # Verificar se encontrou informa√ß√µes
        if "n√£o tenho informa√ß√µes" in context.lower() or len(context) < 30:
            print("\nViajero: Desculpe, n√£o encontrei informa√ß√µes sobre esse destino no meu guia.")
            print("Posso ajudar com outros destinos ou com dicas gerais de viagem?")
            continue
            
        # Criar e executar a cadeia de processamento
        chain = (
            RunnablePassthrough.assign(
                context=lambda x: context,
                chat_history=lambda x: chat_history.messages
            )
            | prompt
            | llm
            | StrOutputParser()
        )
        
        response = chain.invoke({"input": user_input})
        
        # Atualizar hist√≥rico
        chat_history.add_user_message(user_input)
        chat_history.add_ai_message(response)
        
        print("\nViajero:", response)

if __name__ == "__main__":
    travel_chatbot()